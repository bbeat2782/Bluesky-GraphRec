{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "292c6062-9b34-41b2-bc8b-080e3a8658af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "from pandas.testing import assert_frame_equal\n",
    "from distutils.dir_util import copy_tree\n",
    "from datetime import datetime, timedelta\n",
    "import pickle\n",
    "import time\n",
    "from numba import njit\n",
    "\n",
    "\n",
    "def preprocess(dataset_name: str):\n",
    "    \"\"\"\n",
    "    read the original data file and return the DataFrame that has columns ['u', 'i', 'ts', 'label', 'idx']\n",
    "    :param dataset_name: str, dataset name\n",
    "    :return:\n",
    "    \"\"\"    \n",
    "    u_list, i_list, ts_list, label_list = [], [], [], []\n",
    "    feat_l = []\n",
    "    idx_list = []\n",
    "\n",
    "    with open(dataset_name) as f:\n",
    "        # skip the first line\n",
    "        s = next(f)\n",
    "        previous_time = -1\n",
    "        for idx, line in enumerate(f):\n",
    "            e = line.strip().split(',')\n",
    "            # user_id\n",
    "            u = int(e[0])\n",
    "            # item_id\n",
    "            i = int(e[1])\n",
    "\n",
    "            # timestamp\n",
    "            ts = float(e[2])\n",
    "            # check whether time in ascending order\n",
    "            # TODO : Check if we can get second from like history\n",
    "            assert ts >= previous_time\n",
    "            previous_time = ts\n",
    "            # state_label\n",
    "            label = float(e[3])\n",
    "\n",
    "            # edge features --> dataset_name.csv does not have e[4:]\n",
    "            # feat = np.array([float(x) for x in e[4:]])\n",
    "            feat = np.array([0.0, 0.0])  # dim 2 with zeros\n",
    "\n",
    "            #feat = item_embeddings.get(i, np.zeros_like(list(item_embeddings.values())[0]))  # Default to zeros if missing\n",
    "\n",
    "            u_list.append(u)\n",
    "            i_list.append(i)\n",
    "            ts_list.append(ts)\n",
    "            label_list.append(label)\n",
    "            # edge index\n",
    "            idx_list.append(idx)\n",
    "\n",
    "            feat_l.append(feat)\n",
    "    return pd.DataFrame({'u': u_list,\n",
    "                         'i': i_list,\n",
    "                         'ts': ts_list,\n",
    "                         'label': label_list,\n",
    "                         'idx': idx_list}), np.array(feat_l)\n",
    "\n",
    "\n",
    "def reindex(df: pd.DataFrame, bipartite: bool = True):\n",
    "    \"\"\"\n",
    "    reindex the ids of nodes and edges\n",
    "    :param df: DataFrame\n",
    "    :param bipartite: boolean, whether the graph is bipartite or not\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    new_df = df.copy()\n",
    "    if bipartite:\n",
    "        # check the ids of users and items\n",
    "        assert (df.u.max() - df.u.min() + 1 == len(df.u.unique()))\n",
    "        assert (df.i.max() - df.i.min() + 1 == len(df.i.unique()))\n",
    "        assert df.u.min() == df.i.min() == 0\n",
    "\n",
    "        # if bipartite, discriminate the source and target node by unique ids (target node id is counted based on source node id)\n",
    "        upper_u = df.u.max() + 1\n",
    "        new_i = df.i + upper_u\n",
    "\n",
    "        new_df.i = new_i\n",
    "\n",
    "    # make the id start from 1\n",
    "    new_df.u += 1\n",
    "    new_df.i += 1\n",
    "    new_df.idx += 1\n",
    "\n",
    "    return new_df\n",
    "\n",
    "dataset_name='bluesky'\n",
    "bipartite = True\n",
    "node_feat_dim = 128\n",
    "edge_feat_dim = 10\n",
    "\n",
    "Path(\"../processed_data/{}/\".format(dataset_name)).mkdir(parents=True, exist_ok=True)\n",
    "INTERACTION_PATH = '../DG_data/{}/{}.csv'.format(dataset_name, dataset_name)\n",
    "ITEM_EMBEDDINGS_PATH = '../DG_data/{}/{}_text_embeddings.parquet'.format(dataset_name, dataset_name)\n",
    "OUT_DF = '../processed_data/{}/ml_{}.csv'.format(dataset_name, dataset_name)\n",
    "OUT_FEAT = '../processed_data/{}/ml_{}.npy'.format(dataset_name, dataset_name)\n",
    "OUT_NODE_FEAT = '../processed_data/{}/ml_{}_node.npy'.format(dataset_name, dataset_name)\n",
    "OUT_DYNAMIC_USER_FEAT = '../processed_data/{}/ml_{}_user_dynamic.npy'.format(dataset_name, dataset_name)\n",
    "\n",
    "df, edge_feats = preprocess(INTERACTION_PATH)\n",
    "new_df = reindex(df, bipartite)\n",
    "\n",
    "# edge feature for zero index, which is not used (since edge id starts from 1)\n",
    "empty = np.zeros(edge_feats.shape[1])[np.newaxis, :]\n",
    "# Stack arrays in sequence vertically(row wise),\n",
    "edge_feats = np.vstack([empty, edge_feats])\n",
    "\n",
    "# Processing node features from Parquet file\n",
    "text_embeddings = pd.read_parquet(ITEM_EMBEDDINGS_PATH)\n",
    "text_embeddings = text_embeddings.sort_values('item_id').reset_index(drop=True)\n",
    "user_max_id = df.u.max()\n",
    "offset = user_max_id + 2\n",
    "text_embeddings['item_id'] = text_embeddings['item_id'] + offset\n",
    "\n",
    "# TODO check text_embeddings['item_id'].min() and text_embeddings['item_id'].max()\n",
    "# check text_embeddings['item_id'][108706]\n",
    "# check text_embeddings['item_id'][108707]\n",
    "# check text_embeddings['item_id'][108708]\n",
    "\n",
    "# node features with one additional feature for zero index (since node id starts from 1)\n",
    "max_idx = max(new_df.u.max(), new_df.i.max())\n",
    "node_feats = np.zeros((max_idx + 1, node_feat_dim))\n",
    "\n",
    "# storing post embeddings\n",
    "for _, row in text_embeddings.iterrows():\n",
    "    global_item_id = row['item_id']\n",
    "    node_feats[global_item_id] = row['embeddings']\n",
    "    \n",
    "start_time = time.time()\n",
    "# Current format of ts: `20230101024321.0` (`YYYYMMDDHHMMSS`) --> change to datetime obj\n",
    "new_df['ts'] = pd.to_datetime(new_df['ts'].astype(int).astype(str), format='%Y%m%d%H%M%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3afa49a2-6dcf-482d-80d2-61f43ea62641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       u        i                  ts  label  idx\n",
      "0  12249   107717 2023-01-01 02:43:21    0.0    1\n",
      "1  50948  3150865 2023-01-01 02:49:54    0.0    2\n",
      "2  24219  2454231 2023-01-01 03:52:02    0.0    3\n",
      "3  13744   107717 2023-01-01 05:16:55    0.0    4\n",
      "4  50948   107717 2023-01-01 05:35:02    0.0    5\n",
      "   item_id                                         embeddings\n",
      "0   106368  [0.1220703125, -0.250732421875, 0.176391601562...\n",
      "1   106369  [0.15185546875, -0.2293701171875, -0.085998535...\n",
      "2   106370  [0.0938720703125, -0.273193359375, 0.049560546...\n",
      "3   106371  [0.1522216796875, -0.230712890625, 0.088928222...\n",
      "4   106372  [0.1571044921875, -0.260009765625, 0.128417968...\n"
     ]
    }
   ],
   "source": [
    "print(new_df.head(5))\n",
    "print(text_embeddings.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "968236bb-c7ad-4213-96ff-d86cc41b407a",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_size = 10\n",
    "\n",
    "# Ensure dataframe is sorted\n",
    "new_df = new_df.sort_values(by=['u', 'ts']).reset_index(drop=True)\n",
    "\n",
    "# Convert to NumPy for fast access\n",
    "user_ids = new_df['u'].values\n",
    "item_ids = new_df['i'].values\n",
    "embeddings = node_feats[item_ids].astype(np.float16)  # Direct NumPy lookup\n",
    "\n",
    "# Initialize output array\n",
    "user_dynamic_features = np.zeros_like(embeddings, dtype=np.float16)\n",
    "\n",
    "# Process in batch using NumPy slicing\n",
    "unique_users, user_starts = np.unique(user_ids, return_index=True)\n",
    "for idx, start in enumerate(user_starts):\n",
    "    end = user_starts[idx + 1] if idx + 1 < len(user_starts) else len(user_ids)\n",
    "    \n",
    "    user_embeds = embeddings[start:end]  # Extract all embeddings for this user\n",
    "    num_interactions = len(user_embeds)\n",
    "\n",
    "    if num_interactions == 1:\n",
    "        # If only one interaction exists, set to zeros (no past interactions to average)\n",
    "        user_dynamic_features[start:end] = np.zeros_like(user_embeds)\n",
    "        continue\n",
    "\n",
    "    # Compute cumulative sum\n",
    "    cumsum = np.cumsum(user_embeds, axis=0)\n",
    "\n",
    "    # Compute rolling sum while excluding current embedding\n",
    "    rolling_sum = np.zeros_like(user_embeds)\n",
    "    for i in range(num_interactions):\n",
    "        start_idx = max(0, i - history_size)\n",
    "        past_sum = cumsum[i - 1] - (cumsum[start_idx - 1] if start_idx > 0 else 0)\n",
    "        rolling_sum[i] = past_sum\n",
    "\n",
    "    # Compute rolling mean excluding the current embedding\n",
    "    valid_counts = np.minimum(np.arange(num_interactions), history_size)[:, None]  # Excludes current element\n",
    "    rolling_mean = rolling_sum / np.maximum(valid_counts, 1)  # Avoid division by zero\n",
    "\n",
    "    # Explicitly set the first interaction to a zero vector\n",
    "    rolling_mean[0] = np.zeros_like(user_embeds[0])\n",
    "\n",
    "    # Store result\n",
    "    user_dynamic_features[start:end] = rolling_mean\n",
    "\n",
    "# Restore the original order before saving\n",
    "new_df['user_dynamic_features'] = list(user_dynamic_features)\n",
    "new_df = new_df.sort_values(by='idx')\n",
    "\n",
    "np.savez_compressed(\"/home/sgan/user_dynamic_features.npz\", \n",
    "                    user_dynamic_features=np.array(new_df['user_dynamic_features'].tolist(), dtype=np.float16))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fb9c411-3046-46ca-a92e-de1374fff62a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u</th>\n",
       "      <th>i</th>\n",
       "      <th>ts</th>\n",
       "      <th>label</th>\n",
       "      <th>idx</th>\n",
       "      <th>user_dynamic_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>3</td>\n",
       "      <td>106928</td>\n",
       "      <td>2023-06-08 16:07:18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13910232</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>3</td>\n",
       "      <td>106929</td>\n",
       "      <td>2023-06-08 16:11:38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13911157</td>\n",
       "      <td>[0.204, -0.279, 0.07135, 0.0319, 0.1864, -0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>3</td>\n",
       "      <td>106930</td>\n",
       "      <td>2023-06-08 21:55:18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13987360</td>\n",
       "      <td>[0.1716, -0.2878, 0.0825, 0.0567, 0.1447, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>3</td>\n",
       "      <td>106931</td>\n",
       "      <td>2023-06-08 21:55:41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13987438</td>\n",
       "      <td>[0.1815, -0.2477, 0.03207, 0.06198, 0.1148, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>3</td>\n",
       "      <td>106932</td>\n",
       "      <td>2023-06-10 02:29:16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14316411</td>\n",
       "      <td>[0.1498, -0.2612, 0.03467, 0.06573, 0.1068, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>3</td>\n",
       "      <td>106933</td>\n",
       "      <td>2023-06-10 07:37:55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14359045</td>\n",
       "      <td>[0.1654, -0.2617, 0.02531, 0.05142, 0.1234, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>3</td>\n",
       "      <td>106934</td>\n",
       "      <td>2023-06-10 07:38:44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14359126</td>\n",
       "      <td>[0.1578, -0.253, 0.0507, 0.04785, 0.11835, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>3</td>\n",
       "      <td>106935</td>\n",
       "      <td>2023-06-15 04:39:36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15649295</td>\n",
       "      <td>[0.1571, -0.2422, 0.03223, 0.03937, 0.1255, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      u       i                  ts  label       idx  \\\n",
       "1068  3  106928 2023-06-08 16:07:18    0.0  13910232   \n",
       "1069  3  106929 2023-06-08 16:11:38    0.0  13911157   \n",
       "1070  3  106930 2023-06-08 21:55:18    0.0  13987360   \n",
       "1071  3  106931 2023-06-08 21:55:41    0.0  13987438   \n",
       "1072  3  106932 2023-06-10 02:29:16    0.0  14316411   \n",
       "1073  3  106933 2023-06-10 07:37:55    0.0  14359045   \n",
       "1074  3  106934 2023-06-10 07:38:44    0.0  14359126   \n",
       "1075  3  106935 2023-06-15 04:39:36    0.0  15649295   \n",
       "\n",
       "                                  user_dynamic_features  \n",
       "1068  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1069  [0.204, -0.279, 0.07135, 0.0319, 0.1864, -0.02...  \n",
       "1070  [0.1716, -0.2878, 0.0825, 0.0567, 0.1447, -0.0...  \n",
       "1071  [0.1815, -0.2477, 0.03207, 0.06198, 0.1148, -0...  \n",
       "1072  [0.1498, -0.2612, 0.03467, 0.06573, 0.1068, -0...  \n",
       "1073  [0.1654, -0.2617, 0.02531, 0.05142, 0.1234, -0...  \n",
       "1074  [0.1578, -0.253, 0.0507, 0.04785, 0.11835, -0....  \n",
       "1075  [0.1571, -0.2422, 0.03223, 0.03937, 0.1255, -0...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df[new_df['u']==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97990d68-5c2d-478e-a9a5-f2c705424499",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bluesky",
   "language": "python",
   "name": "bluesky"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
