{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First embedding shape: 128\n",
      "   item_id                                         embeddings\n",
      "0  3460233  [1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, ...\n",
      "1  3044498  [1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, ...\n",
      "2  1582998  [1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, ...\n",
      "3  5436174  [1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, ...\n",
      "4  1582999  [1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, ...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the parquet file\n",
    "df = pd.read_parquet(\"data/bluesky_text_embeddings (1).parquet\")\n",
    "\n",
    "# Unpack the binary embeddings\n",
    "def unpack_embeddings(packed_bytes):\n",
    "    return np.unpackbits(np.frombuffer(packed_bytes, dtype=np.uint8))\n",
    "\n",
    "# Apply unpacking to get original binary embeddings\n",
    "df['embeddings'] = df['embeddings'].apply(unpack_embeddings)\n",
    "\n",
    "# Now you can look at the first few rows to verify\n",
    "print(\"First embedding shape:\", len(df['embeddings'].iloc[0]))\n",
    "print(df[['item_id', 'embeddings']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final DataFrame shape: (16943200, 8)\n",
      "\n",
      "Columns: ['source_node', 'destination_node', 'timestamp', 'edge_label', 'item_id', 'embeddings', 'user_id', 'user_embedding']\n",
      "\n",
      "Sample user-post pair:\n",
      "User ID: 50947\n",
      "Post ID: 3460233\n",
      "User embedding (first 10): [0.96829477 0.         0.86032562 0.48671808 0.95886889 0.04798629\n",
      " 0.15595544 0.9991431  0.46615253 0.48500428]\n",
      "Post embedding (first 10): [1 0 1 1 1 0 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import duckdb\n",
    "\n",
    "# 1. Load and unpack embeddings\n",
    "con = duckdb.connect()\n",
    "con.execute(\"\"\"\n",
    "    CREATE TABLE embeddings AS SELECT * FROM read_parquet('data/bluesky_text_embeddings (1).parquet');\n",
    "\"\"\")\n",
    "post_embeddings_df = con.execute(\"SELECT * FROM embeddings\").fetchdf()\n",
    "\n",
    "def unpack_embeddings(packed_bytes):\n",
    "    return np.unpackbits(np.frombuffer(packed_bytes, dtype=np.uint8))\n",
    "\n",
    "post_embeddings_df['embeddings'] = post_embeddings_df['embeddings'].apply(unpack_embeddings)\n",
    "\n",
    "# 2. Load interactions\n",
    "con.execute(\"\"\"\n",
    "    CREATE TABLE interactions AS SELECT * FROM read_csv('data/bluesky.csv');\n",
    "\"\"\")\n",
    "interactions_df = con.execute(\"SELECT * FROM interactions\").fetchdf()\n",
    "\n",
    "# 3. Join interactions with post embeddings\n",
    "joined_df = interactions_df.merge(\n",
    "    post_embeddings_df,\n",
    "    left_on='destination_node',\n",
    "    right_on='item_id',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# 4. Group by user and create user embeddings\n",
    "user_embeddings = joined_df.groupby('source_node')['embeddings'].agg(\n",
    "    lambda x: np.mean(list(x), axis=0)\n",
    ").reset_index()\n",
    "user_embeddings.columns = ['user_id', 'user_embedding']\n",
    "\n",
    "# 5. Create final DataFrame with all information\n",
    "final_df = joined_df.merge(\n",
    "    user_embeddings,\n",
    "    left_on='source_node',\n",
    "    right_on='user_id',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Verify the data\n",
    "print(\"Final DataFrame shape:\", final_df.shape)\n",
    "print(\"\\nColumns:\", final_df.columns.tolist())\n",
    "print(\"\\nSample user-post pair:\")\n",
    "sample = final_df.iloc[0]\n",
    "print(f\"User ID: {sample['source_node']}\")\n",
    "print(f\"Post ID: {sample['destination_node']}\")\n",
    "print(f\"User embedding (first 10):\", sample['user_embedding'][:10])\n",
    "print(f\"Post embedding (first 10):\", sample['embeddings'][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 35444:\n",
      "Number of liked posts: 299\n",
      "\n",
      "User embedding (first 20 values):\n",
      "[0.95317726 0.         0.85284281 0.56856187 0.9632107  0.05685619\n",
      " 0.13043478 0.98996656 0.4548495  0.55518395 0.34448161 1.\n",
      " 0.33110368 0.11371237 0.05016722 0.33779264 0.03344482 0.94983278\n",
      " 0.55518395 0.5819398 ]\n",
      "\n",
      "Liked posts embeddings (first 3 posts, first 20 values):\n",
      "Post 0: [1 0 0 1 1 0 0 1 1 0 0 1 0 0 0 0 0 1 1 0]\n",
      "Post 1: [1 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 0 1 1 1]\n",
      "Post 2: [1 0 0 1 1 0 0 1 1 1 0 1 0 0 0 1 0 1 1 1]\n",
      "Post 3: [1 0 1 1 1 0 0 1 0 0 0 1 0 1 0 0 0 1 0 1]\n",
      "Post 4: [1 0 1 1 1 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0]\n",
      "Post 5: [1 0 1 0 0 0 0 1 1 1 0 1 1 1 0 0 0 1 1 0]\n",
      "Post 6: [1 0 1 0 1 0 0 1 0 0 1 1 0 0 0 0 0 1 1 0]\n",
      "Post 7: [1 0 1 1 1 0 0 1 0 0 1 1 0 0 0 1 0 1 0 1]\n",
      "Post 8: [1 0 1 1 1 0 0 1 0 1 0 1 1 0 0 0 0 1 1 0]\n",
      "\n",
      "Verification - are user embeddings the average of liked posts?\n",
      "Max difference: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Pick a random user_id to examine\n",
    "user_id = final_df['user_id'].iloc[21]\n",
    "\n",
    "# Get their embedding\n",
    "user_emb = final_df[final_df['user_id'] == user_id]['user_embedding'].iloc[0]\n",
    "\n",
    "# Get all posts this user liked\n",
    "liked_posts = final_df[final_df['user_id'] == user_id]['destination_node'].values\n",
    "\n",
    "# Get embeddings for these posts\n",
    "liked_post_embeddings = post_embeddings_df[post_embeddings_df['item_id'].isin(liked_posts)]['embeddings'].values\n",
    "\n",
    "print(f\"User {user_id}:\")\n",
    "print(f\"Number of liked posts: {len(liked_posts)}\")\n",
    "print(f\"\\nUser embedding (first 20 values):\\n{user_emb[:20]}\")\n",
    "print(f\"\\nLiked posts embeddings (first 3 posts, first 20 values):\")\n",
    "for i, emb in enumerate(liked_post_embeddings[:9]):\n",
    "    print(f\"Post {i}: {emb[:20]}\")\n",
    "\n",
    "# Verify that user embedding is indeed the average\n",
    "avg_liked_embeddings = np.mean(liked_post_embeddings, axis=0)\n",
    "print(f\"\\nVerification - are user embeddings the average of liked posts?\")\n",
    "print(f\"Max difference: {np.max(np.abs(user_emb - avg_liked_embeddings))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from model import UserTower, PostTower, TwoTowerModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "\n",
    "class UserPostDataset(Dataset):\n",
    "    def __init__(self, df, negative_samples=1):\n",
    "        self.df = df\n",
    "        self.negative_samples = negative_samples\n",
    "        # Precompute user's positive posts for faster lookup\n",
    "        self.user_positives = {\n",
    "            user: set(group['destination_node'].values) \n",
    "            for user, group in df.groupby('source_node')\n",
    "        }\n",
    "        self.all_posts = df['destination_node'].unique()\n",
    "        # Calculate total length including negative samples\n",
    "        self.length = len(df) * (self.negative_samples + 1)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.length  # Return integer length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        interaction_idx = idx // (self.negative_samples + 1)\n",
    "        is_positive = idx % (self.negative_samples + 1) == 0\n",
    "        \n",
    "        row = self.df.iloc[interaction_idx]\n",
    "        user_id = row['source_node']\n",
    "        \n",
    "        if is_positive:\n",
    "            post_emb = row['embeddings']\n",
    "            user_emb = row['user_embedding']\n",
    "        else:\n",
    "            # Simple random sampling without checking\n",
    "            neg_post_idx = np.random.choice(len(self.df))\n",
    "            neg_post = self.df.iloc[neg_post_idx]\n",
    "            post_emb = neg_post['embeddings']\n",
    "            user_emb = row['user_embedding']\n",
    "        \n",
    "        return (\n",
    "            torch.tensor(user_emb, dtype=torch.float32),\n",
    "            torch.tensor(post_emb, dtype=torch.float32),\n",
    "            torch.tensor(1.0 if is_positive else 0.0, dtype=torch.float32)\n",
    "        )\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_df, val_df = train_test_split(final_df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = UserPostDataset(train_df)\n",
    "val_dataset = UserPostDataset(val_df)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1024, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2. Split data and create dataloaders\n",
    "# train_df, val_df = train_test_split(final_df, test_size=0.2, random_state=42)\n",
    "# all_post_ids = final_df['destination_node'].unique()\n",
    "\n",
    "# train_dataset = UserPostDataset(train_df, all_post_ids)\n",
    "# val_dataset = UserPostDataset(val_df, all_post_ids)\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=4)\n",
    "\n",
    "# # 3. Initialize model\n",
    "# embedding_dim = len(final_df['embeddings'].iloc[0])  # Should be 128\n",
    "# hidden_dims = [64, 32]\n",
    "\n",
    "# user_tower = UserTower(embedding_dim=embedding_dim, hidden_dims=hidden_dims)\n",
    "# post_tower = PostTower(embedding_dim=embedding_dim, hidden_dims=hidden_dims)\n",
    "# model = TwoTowerModel(user_tower, post_tower)\n",
    "\n",
    "# # 4. Training setup\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# print(f\"Using device: {device}\")\n",
    "\n",
    "# model = model.to(device)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# 5. Training loop\n",
    "# num_epochs = 3\n",
    "# best_val_loss = float('inf')\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     # Training phase\n",
    "#     model.train()\n",
    "#     train_loss = 0\n",
    "#     for batch_idx, (user_features, post_features, labels) in enumerate(train_loader):\n",
    "#         user_features = user_features.to(device)\n",
    "#         post_features = post_features.to(device)\n",
    "#         labels = labels.to(device)\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "#         user_emb, post_emb = model(user_features, post_features)\n",
    "        \n",
    "#         # Compute similarity scores\n",
    "#         scores = torch.sum(user_emb * post_emb, dim=1)\n",
    "#         loss = criterion(scores, labels)\n",
    "        \n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         train_loss += loss.item()\n",
    "        \n",
    "#         if batch_idx % 100 == 0:\n",
    "#             print(f'Epoch {epoch}, Batch {batch_idx}, Loss: {loss.item():.4f}')\n",
    "    \n",
    "#     avg_train_loss = train_loss / len(train_loader)\n",
    "    \n",
    "#     # Validation phase\n",
    "#     model.eval()\n",
    "#     val_loss = 0\n",
    "#     correct_predictions = 0\n",
    "#     total_predictions = 0\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for user_features, post_features, labels in val_loader:\n",
    "#             user_features = user_features.to(device)\n",
    "#             post_features = post_features.to(device)\n",
    "#             labels = labels.to(device)\n",
    "            \n",
    "#             user_emb, post_emb = model(user_features, post_features)\n",
    "#             scores = torch.sum(user_emb * post_emb, dim=1)\n",
    "#             loss = criterion(scores, labels)\n",
    "            \n",
    "#             val_loss += loss.item()\n",
    "            \n",
    "#             # Calculate accuracy\n",
    "#             predictions = (torch.sigmoid(scores) > 0.5).float()\n",
    "#             correct_predictions += (predictions == labels).sum().item()\n",
    "#             total_predictions += labels.size(0)\n",
    "    \n",
    "#     avg_val_loss = val_loss / len(val_loader)\n",
    "#     accuracy = correct_predictions / total_predictions\n",
    "    \n",
    "#     print(f'Epoch {epoch}:')\n",
    "#     print(f'  Training Loss: {avg_train_loss:.4f}')\n",
    "#     print(f'  Validation Loss: {avg_val_loss:.4f}')\n",
    "#     print(f'  Validation Accuracy: {accuracy:.4f}')\n",
    "    \n",
    "#     # Save best model\n",
    "#     if avg_val_loss < best_val_loss:\n",
    "#         best_val_loss = avg_val_loss\n",
    "#         torch.save(model.state_dict(), 'best_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim=128\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/26474 [00:02<17:32:25,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 statistics:\n",
      "  Loss: 0.7016\n",
      "  Gradient norm: 0.3347\n",
      "  Score range: [-0.0336, 0.4606]\n",
      "  Prediction mean: 0.5540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 105/26474 [00:06<17:52, 24.58it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 100 statistics:\n",
      "  Loss: 0.6425\n",
      "  Gradient norm: 0.2732\n",
      "  Score range: [-0.9322, 0.9787]\n",
      "  Prediction mean: 0.5250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 203/26474 [00:10<18:57, 23.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 200 statistics:\n",
      "  Loss: 0.6208\n",
      "  Gradient norm: 0.1968\n",
      "  Score range: [-0.9408, 0.9831]\n",
      "  Prediction mean: 0.5263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 302/26474 [00:14<16:11, 26.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 300 statistics:\n",
      "  Loss: 0.6329\n",
      "  Gradient norm: 0.1626\n",
      "  Score range: [-0.9465, 0.9658]\n",
      "  Prediction mean: 0.5216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 405/26474 [00:20<19:47, 21.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 400 statistics:\n",
      "  Loss: 0.6214\n",
      "  Gradient norm: 0.1214\n",
      "  Score range: [-0.9389, 0.9417]\n",
      "  Prediction mean: 0.5351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 504/26474 [00:24<15:09, 28.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 500 statistics:\n",
      "  Loss: 0.6231\n",
      "  Gradient norm: 0.1655\n",
      "  Score range: [-0.9722, 0.9068]\n",
      "  Prediction mean: 0.5223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 604/26474 [00:28<16:37, 25.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 600 statistics:\n",
      "  Loss: 0.6253\n",
      "  Gradient norm: 0.2467\n",
      "  Score range: [-0.9565, 0.9417]\n",
      "  Prediction mean: 0.5328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 704/26474 [00:31<15:58, 26.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 700 statistics:\n",
      "  Loss: 0.6255\n",
      "  Gradient norm: 0.1783\n",
      "  Score range: [-0.9539, 0.9327]\n",
      "  Prediction mean: 0.5311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 800/26474 [00:35<15:27, 27.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 800 statistics:\n",
      "  Loss: 0.6208\n",
      "  Gradient norm: 0.2681\n",
      "  Score range: [-0.9482, 0.9709]\n",
      "  Prediction mean: 0.5380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 904/26474 [00:40<15:59, 26.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 900 statistics:\n",
      "  Loss: 0.6235\n",
      "  Gradient norm: 0.1917\n",
      "  Score range: [-0.9608, 0.9313]\n",
      "  Prediction mean: 0.5224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1004/26474 [00:44<15:11, 27.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1000 statistics:\n",
      "  Loss: 0.6174\n",
      "  Gradient norm: 0.1815\n",
      "  Score range: [-0.9564, 0.9387]\n",
      "  Prediction mean: 0.5342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1104/26474 [00:48<15:27, 27.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1100 statistics:\n",
      "  Loss: 0.6143\n",
      "  Gradient norm: 0.1605\n",
      "  Score range: [-0.9444, 0.9658]\n",
      "  Prediction mean: 0.5346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 1204/26474 [00:51<15:25, 27.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1200 statistics:\n",
      "  Loss: 0.6212\n",
      "  Gradient norm: 0.1902\n",
      "  Score range: [-0.9542, 0.9573]\n",
      "  Prediction mean: 0.5362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 1303/26474 [00:56<17:51, 23.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1300 statistics:\n",
      "  Loss: 0.6218\n",
      "  Gradient norm: 0.1377\n",
      "  Score range: [-0.9504, 0.9365]\n",
      "  Prediction mean: 0.5294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1405/26474 [01:00<15:30, 26.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1400 statistics:\n",
      "  Loss: 0.6203\n",
      "  Gradient norm: 0.1513\n",
      "  Score range: [-0.9668, 0.8909]\n",
      "  Prediction mean: 0.5312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 1505/26474 [01:04<14:45, 28.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1500 statistics:\n",
      "  Loss: 0.6221\n",
      "  Gradient norm: 0.1652\n",
      "  Score range: [-0.9579, 0.9359]\n",
      "  Prediction mean: 0.5303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 1605/26474 [01:07<15:47, 26.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1600 statistics:\n",
      "  Loss: 0.6274\n",
      "  Gradient norm: 0.1423\n",
      "  Score range: [-0.9553, 0.9410]\n",
      "  Prediction mean: 0.5177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 1701/26474 [01:11<16:07, 25.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1700 statistics:\n",
      "  Loss: 0.6230\n",
      "  Gradient norm: 0.1592\n",
      "  Score range: [-0.9750, 0.9436]\n",
      "  Prediction mean: 0.5369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1805/26474 [01:16<15:23, 26.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1800 statistics:\n",
      "  Loss: 0.6118\n",
      "  Gradient norm: 0.1620\n",
      "  Score range: [-0.9704, 0.9359]\n",
      "  Prediction mean: 0.5293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1903/26474 [01:20<16:02, 25.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1900 statistics:\n",
      "  Loss: 0.6177\n",
      "  Gradient norm: 0.1992\n",
      "  Score range: [-0.9732, 0.9307]\n",
      "  Prediction mean: 0.5391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2007/26474 [01:24<13:26, 30.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2000 statistics:\n",
      "  Loss: 0.6292\n",
      "  Gradient norm: 0.1568\n",
      "  Score range: [-0.9637, 0.9112]\n",
      "  Prediction mean: 0.5304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2102/26474 [01:27<15:49, 25.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2100 statistics:\n",
      "  Loss: 0.6172\n",
      "  Gradient norm: 0.1531\n",
      "  Score range: [-0.9628, 0.9354]\n",
      "  Prediction mean: 0.5355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2203/26474 [01:32<24:23, 16.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2200 statistics:\n",
      "  Loss: 0.6199\n",
      "  Gradient norm: 0.1506\n",
      "  Score range: [-0.9627, 0.9346]\n",
      "  Prediction mean: 0.5326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 2305/26474 [01:36<15:52, 25.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2300 statistics:\n",
      "  Loss: 0.6147\n",
      "  Gradient norm: 0.1358\n",
      "  Score range: [-0.9579, 0.9107]\n",
      "  Prediction mean: 0.5312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 2405/26474 [01:40<13:50, 28.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2400 statistics:\n",
      "  Loss: 0.6217\n",
      "  Gradient norm: 0.1244\n",
      "  Score range: [-0.9505, 0.9392]\n",
      "  Prediction mean: 0.5323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 2505/26474 [01:44<15:55, 25.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2500 statistics:\n",
      "  Loss: 0.6171\n",
      "  Gradient norm: 0.1463\n",
      "  Score range: [-0.9678, 0.9315]\n",
      "  Prediction mean: 0.5206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 2602/26474 [01:48<16:40, 23.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2600 statistics:\n",
      "  Loss: 0.6172\n",
      "  Gradient norm: 0.1306\n",
      "  Score range: [-0.9508, 0.9429]\n",
      "  Prediction mean: 0.5363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2705/26474 [01:53<14:43, 26.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2700 statistics:\n",
      "  Loss: 0.6205\n",
      "  Gradient norm: 0.1056\n",
      "  Score range: [-0.9796, 0.9588]\n",
      "  Prediction mean: 0.5415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 2805/26474 [01:56<14:34, 27.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2800 statistics:\n",
      "  Loss: 0.6165\n",
      "  Gradient norm: 0.1270\n",
      "  Score range: [-0.9441, 0.9450]\n",
      "  Prediction mean: 0.5367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 2905/26474 [02:00<14:12, 27.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2900 statistics:\n",
      "  Loss: 0.6005\n",
      "  Gradient norm: 0.1210\n",
      "  Score range: [-0.9529, 0.9165]\n",
      "  Prediction mean: 0.5284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 3005/26474 [02:04<16:02, 24.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3000 statistics:\n",
      "  Loss: 0.6021\n",
      "  Gradient norm: 0.1537\n",
      "  Score range: [-0.9519, 0.9377]\n",
      "  Prediction mean: 0.5308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3101/26474 [02:09<22:44, 17.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3100 statistics:\n",
      "  Loss: 0.6149\n",
      "  Gradient norm: 0.1252\n",
      "  Score range: [-0.9553, 0.9437]\n",
      "  Prediction mean: 0.5390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3205/26474 [02:14<16:43, 23.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3200 statistics:\n",
      "  Loss: 0.6007\n",
      "  Gradient norm: 0.1152\n",
      "  Score range: [-0.9726, 0.9210]\n",
      "  Prediction mean: 0.5338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3305/26474 [02:18<17:25, 22.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3300 statistics:\n",
      "  Loss: 0.6122\n",
      "  Gradient norm: 0.1198\n",
      "  Score range: [-0.9545, 0.9337]\n",
      "  Prediction mean: 0.5457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 3401/26474 [02:23<19:42, 19.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3400 statistics:\n",
      "  Loss: 0.6175\n",
      "  Gradient norm: 0.1488\n",
      "  Score range: [-0.9459, 0.9194]\n",
      "  Prediction mean: 0.5369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 3501/26474 [02:28<18:45, 20.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3500 statistics:\n",
      "  Loss: 0.6161\n",
      "  Gradient norm: 0.1203\n",
      "  Score range: [-0.9535, 0.9433]\n",
      "  Prediction mean: 0.5400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 3605/26474 [02:35<16:51, 22.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3600 statistics:\n",
      "  Loss: 0.6341\n",
      "  Gradient norm: 0.1700\n",
      "  Score range: [-0.9597, 0.9212]\n",
      "  Prediction mean: 0.5310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 3705/26474 [02:39<15:14, 24.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3700 statistics:\n",
      "  Loss: 0.6163\n",
      "  Gradient norm: 0.0921\n",
      "  Score range: [-0.9557, 0.9517]\n",
      "  Prediction mean: 0.5390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 3805/26474 [02:43<16:51, 22.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3800 statistics:\n",
      "  Loss: 0.6197\n",
      "  Gradient norm: 0.1274\n",
      "  Score range: [-0.9781, 0.9514]\n",
      "  Prediction mean: 0.5511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 3905/26474 [02:48<15:55, 23.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3900 statistics:\n",
      "  Loss: 0.6240\n",
      "  Gradient norm: 0.1080\n",
      "  Score range: [-0.9568, 0.9673]\n",
      "  Prediction mean: 0.5442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 4005/26474 [02:53<25:20, 14.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4000 statistics:\n",
      "  Loss: 0.6276\n",
      "  Gradient norm: 0.1529\n",
      "  Score range: [-0.9506, 0.9269]\n",
      "  Prediction mean: 0.5327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 4105/26474 [02:57<14:58, 24.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4100 statistics:\n",
      "  Loss: 0.6260\n",
      "  Gradient norm: 0.1250\n",
      "  Score range: [-0.9471, 0.9455]\n",
      "  Prediction mean: 0.5394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 4205/26474 [03:01<15:16, 24.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4200 statistics:\n",
      "  Loss: 0.6176\n",
      "  Gradient norm: 0.1327\n",
      "  Score range: [-0.9640, 0.9419]\n",
      "  Prediction mean: 0.5385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 4305/26474 [03:05<14:43, 25.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4300 statistics:\n",
      "  Loss: 0.6250\n",
      "  Gradient norm: 0.1025\n",
      "  Score range: [-0.9656, 0.9590]\n",
      "  Prediction mean: 0.5412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 4405/26474 [03:09<14:30, 25.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4400 statistics:\n",
      "  Loss: 0.6172\n",
      "  Gradient norm: 0.1984\n",
      "  Score range: [-0.9772, 0.9504]\n",
      "  Prediction mean: 0.5460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 4504/26474 [03:14<16:21, 22.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4500 statistics:\n",
      "  Loss: 0.6206\n",
      "  Gradient norm: 0.1108\n",
      "  Score range: [-0.9644, 0.9503]\n",
      "  Prediction mean: 0.5392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 4604/26474 [03:18<13:27, 27.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4600 statistics:\n",
      "  Loss: 0.6196\n",
      "  Gradient norm: 0.1458\n",
      "  Score range: [-0.9625, 0.9402]\n",
      "  Prediction mean: 0.5375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 4704/26474 [03:21<13:19, 27.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4700 statistics:\n",
      "  Loss: 0.6183\n",
      "  Gradient norm: 0.1248\n",
      "  Score range: [-0.9532, 0.9442]\n",
      "  Prediction mean: 0.5422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 4804/26474 [03:25<13:53, 26.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4800 statistics:\n",
      "  Loss: 0.6057\n",
      "  Gradient norm: 0.1841\n",
      "  Score range: [-0.9492, 0.9452]\n",
      "  Prediction mean: 0.5270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 4905/26474 [03:30<21:48, 16.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4900 statistics:\n",
      "  Loss: 0.6115\n",
      "  Gradient norm: 0.1042\n",
      "  Score range: [-0.9673, 0.9383]\n",
      "  Prediction mean: 0.5351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 5004/26474 [03:34<12:57, 27.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5000 statistics:\n",
      "  Loss: 0.6136\n",
      "  Gradient norm: 0.1142\n",
      "  Score range: [-0.9528, 0.9511]\n",
      "  Prediction mean: 0.5369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 5104/26474 [03:38<13:55, 25.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5100 statistics:\n",
      "  Loss: 0.6111\n",
      "  Gradient norm: 0.1751\n",
      "  Score range: [-0.9312, 0.9586]\n",
      "  Prediction mean: 0.5364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 5204/26474 [03:41<12:41, 27.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5200 statistics:\n",
      "  Loss: 0.6109\n",
      "  Gradient norm: 0.1433\n",
      "  Score range: [-0.9518, 0.9301]\n",
      "  Prediction mean: 0.5314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 5302/26474 [03:45<13:48, 25.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5300 statistics:\n",
      "  Loss: 0.6100\n",
      "  Gradient norm: 0.1525\n",
      "  Score range: [-0.9866, 0.9516]\n",
      "  Prediction mean: 0.5365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 5404/26474 [03:50<15:35, 22.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5400 statistics:\n",
      "  Loss: 0.6177\n",
      "  Gradient norm: 0.1575\n",
      "  Score range: [-0.9549, 0.9290]\n",
      "  Prediction mean: 0.5318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 5504/26474 [03:54<13:06, 26.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5500 statistics:\n",
      "  Loss: 0.6102\n",
      "  Gradient norm: 0.1052\n",
      "  Score range: [-0.9655, 0.9569]\n",
      "  Prediction mean: 0.5387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 5604/26474 [03:58<12:02, 28.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5600 statistics:\n",
      "  Loss: 0.6132\n",
      "  Gradient norm: 0.1262\n",
      "  Score range: [-0.9582, 0.9439]\n",
      "  Prediction mean: 0.5349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 5706/26474 [04:01<13:26, 25.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5700 statistics:\n",
      "  Loss: 0.6247\n",
      "  Gradient norm: 0.1831\n",
      "  Score range: [-0.9769, 0.9391]\n",
      "  Prediction mean: 0.5519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 5805/26474 [04:06<21:02, 16.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5800 statistics:\n",
      "  Loss: 0.6169\n",
      "  Gradient norm: 0.1395\n",
      "  Score range: [-0.9810, 0.9457]\n",
      "  Prediction mean: 0.5348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 5904/26474 [04:10<12:12, 28.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5900 statistics:\n",
      "  Loss: 0.6117\n",
      "  Gradient norm: 0.1665\n",
      "  Score range: [-0.9491, 0.9593]\n",
      "  Prediction mean: 0.5308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 6004/26474 [04:14<12:35, 27.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6000 statistics:\n",
      "  Loss: 0.6226\n",
      "  Gradient norm: 0.1232\n",
      "  Score range: [-0.9592, 0.9420]\n",
      "  Prediction mean: 0.5321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 6104/26474 [04:18<11:56, 28.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6100 statistics:\n",
      "  Loss: 0.6107\n",
      "  Gradient norm: 0.1418\n",
      "  Score range: [-0.9666, 0.9800]\n",
      "  Prediction mean: 0.5400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 6167/26474 [04:20<14:17, 23.67it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 34\u001b[0m\n\u001b[1;32m     28\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mBCEWithLogitsLoss()\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True, num_workers=4)\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# val_loader = DataLoader(val_dataset, batch_size=1024, shuffle=False, num_workers=4)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Training loop with gradient norm monitoring\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (user_features, post_features, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(train_loader)):\n\u001b[1;32m     35\u001b[0m     user_features \u001b[38;5;241m=\u001b[39m user_features\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     36\u001b[0m     post_features \u001b[38;5;241m=\u001b[39m post_features\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/Projects/Bluesky-GraphRec/.venv/lib/python3.10/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/Bluesky-GraphRec/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/Projects/Bluesky-GraphRec/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1448\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1448\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1449\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1451\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/Bluesky-GraphRec/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1412\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1408\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1409\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1410\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1411\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1412\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1413\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1414\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/Projects/Bluesky-GraphRec/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1243\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1230\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1231\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1232\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1241\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1242\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1243\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1244\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1245\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1246\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1247\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1248\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m/usr/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Modified model with simpler architecture for testing\n",
    "class SimpleTwoTowerModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.user_tower = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "        )\n",
    "        self.post_tower = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "        )\n",
    "        \n",
    "    def forward(self, user_features, post_features):\n",
    "        user_emb = F.normalize(self.user_tower(user_features), p=2, dim=1)\n",
    "        post_emb = F.normalize(self.post_tower(post_features), p=2, dim=1)\n",
    "        return user_emb, post_emb\n",
    "\n",
    "# Try training with this simpler model\n",
    "model = SimpleTwoTowerModel(embedding_dim).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True, num_workers=4)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=1024, shuffle=False, num_workers=4)\n",
    "\n",
    "# Training loop with gradient norm monitoring\n",
    "for batch_idx, (user_features, post_features, labels) in enumerate(tqdm(train_loader)):\n",
    "    user_features = user_features.to(device)\n",
    "    post_features = post_features.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    user_emb, post_emb = model(user_features, post_features)\n",
    "    scores = torch.sum(user_emb * post_emb, dim=1)\n",
    "    loss = criterion(scores, labels)\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    # Monitor gradients\n",
    "    total_norm = 0\n",
    "    for p in model.parameters():\n",
    "        if p.grad is not None:\n",
    "            param_norm = p.grad.data.norm(2)\n",
    "            total_norm += param_norm.item() ** 2\n",
    "    total_norm = total_norm ** 0.5\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    if batch_idx % 1000 == 0:\n",
    "        print(f\"Batch {batch_idx} statistics:\")\n",
    "        print(f\"  Loss: {loss.item():.4f}\")\n",
    "        print(f\"  Gradient norm: {total_norm:.4f}\")\n",
    "        print(f\"  Score range: [{scores.min().item():.4f}, {scores.max().item():.4f}]\")\n",
    "        print(f\"  Prediction mean: {torch.sigmoid(scores).mean().item():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
