{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First embedding shape: 128\n",
      "   item_id                                         embeddings\n",
      "0  3460233  [0.274658203125, -0.10504150390625, 0.07116699...\n",
      "1  3044498  [0.18701171875, -0.1715087890625, -0.009239196...\n",
      "2  1582998  [0.09759521484375, -0.233642578125, -0.0789794...\n",
      "3  5436174  [0.1181640625, -0.2105712890625, 0.00327110290...\n",
      "4  1582999  [0.106201171875, -0.227294921875, -0.018081665...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from model import SimpleTwoTowerModel\n",
    "import duckdb\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load the parquet file\n",
    "df = pd.read_parquet(\"data/bluesky_text_embeddings (2).parquet\")\n",
    "\n",
    "# Unpack the binary embeddings\n",
    "# def unpack_embeddings(packed_bytes):\n",
    "#     return np.unpackbits(np.frombuffer(packed_bytes, dtype=np.uint8))\n",
    "\n",
    "# Apply unpacking to get original binary embeddings\n",
    "# df['embeddings'] = df['embeddings'].apply(unpack_embeddings)\n",
    "\n",
    "# Now you can look at the first few rows to verify\n",
    "print(\"First embedding shape:\", len(df['embeddings'].iloc[0]))\n",
    "print(df[['item_id', 'embeddings']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Embeddings and make finals_df and interactions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final DataFrame shape: (16943200, 8)\n",
      "\n",
      "Columns: ['source_node', 'destination_node', 'timestamp', 'edge_label', 'item_id', 'embeddings', 'user_id', 'user_embedding']\n",
      "\n",
      "Sample user-post pair:\n",
      "User ID: 50947\n",
      "Post ID: 3460233\n",
      "User embedding (first 10): [ 0.15769888 -0.22164886  0.07231304 -0.00327762  0.13493281 -0.12219387\n",
      " -0.07193487  0.22267221 -0.01009528 -0.00120526]\n",
      "Post embedding (first 10): [ 0.2746582  -0.1050415   0.07116699  0.0051651   0.07971191 -0.03967285\n",
      " -0.04690552  0.27392578  0.02571106 -0.04318237]\n"
     ]
    }
   ],
   "source": [
    "# 1. Load and unpack embeddings\n",
    "con = duckdb.connect()\n",
    "con.execute(\"\"\"\n",
    "    CREATE TABLE embeddings AS SELECT * FROM read_parquet('data/bluesky_text_embeddings (2).parquet');\n",
    "\"\"\")\n",
    "post_embeddings_df = con.execute(\"SELECT * FROM embeddings\").fetchdf()\n",
    "\n",
    "# def unpack_embeddings(packed_bytes):\n",
    "#     return np.unpackbits(np.frombuffer(packed_bytes, dtype=np.uint8))\n",
    "\n",
    "# post_embeddings_df['embeddings'] = post_embeddings_df['embeddings'].apply(unpack_embeddings)\n",
    "\n",
    "# 2. Load interactions\n",
    "con.execute(\"\"\"\n",
    "    CREATE TABLE interactions AS SELECT * FROM read_csv('data/bluesky.csv');\n",
    "\"\"\")\n",
    "interactions_df = con.execute(\"SELECT * FROM interactions\").fetchdf()\n",
    "\n",
    "# 3. Join interactions with post embeddings\n",
    "joined_df = interactions_df.merge(\n",
    "    post_embeddings_df,\n",
    "    left_on='destination_node',\n",
    "    right_on='item_id',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# 4. Group by user and create user embeddings\n",
    "user_embeddings = joined_df.groupby('source_node')['embeddings'].agg(\n",
    "    lambda x: np.mean(list(x), axis=0)\n",
    ").reset_index()\n",
    "user_embeddings.columns = ['user_id', 'user_embedding']\n",
    "\n",
    "# 5. Create final DataFrame with all information\n",
    "final_df = joined_df.merge(\n",
    "    user_embeddings,\n",
    "    left_on='source_node',\n",
    "    right_on='user_id',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Verify the data\n",
    "print(\"Final DataFrame shape:\", final_df.shape)\n",
    "print(\"\\nColumns:\", final_df.columns.tolist())\n",
    "print(\"\\nSample user-post pair:\")\n",
    "sample = final_df.iloc[0]\n",
    "print(f\"User ID: {sample['source_node']}\")\n",
    "print(f\"Post ID: {sample['destination_node']}\")\n",
    "print(f\"User embedding (first 10):\", sample['user_embedding'][:10])\n",
    "print(f\"Post embedding (first 10):\", sample['embeddings'][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_node</th>\n",
       "      <th>destination_node</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>edge_label</th>\n",
       "      <th>item_id</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50947</td>\n",
       "      <td>3460233</td>\n",
       "      <td>20230101054209</td>\n",
       "      <td>0</td>\n",
       "      <td>3460233</td>\n",
       "      <td>[0.274658203125, -0.10504150390625, 0.07116699...</td>\n",
       "      <td>50947</td>\n",
       "      <td>[0.15769888380192854, -0.22164885611644441, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50947</td>\n",
       "      <td>1582998</td>\n",
       "      <td>20230101062342</td>\n",
       "      <td>0</td>\n",
       "      <td>1582998</td>\n",
       "      <td>[0.09759521484375, -0.233642578125, -0.0789794...</td>\n",
       "      <td>50947</td>\n",
       "      <td>[0.15769888380192854, -0.22164885611644441, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24218</td>\n",
       "      <td>1582998</td>\n",
       "      <td>20230101065337</td>\n",
       "      <td>0</td>\n",
       "      <td>1582998</td>\n",
       "      <td>[0.09759521484375, -0.233642578125, -0.0789794...</td>\n",
       "      <td>24218</td>\n",
       "      <td>[0.13439939289449532, -0.2052124593859521, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65606</td>\n",
       "      <td>1582998</td>\n",
       "      <td>20230101072700</td>\n",
       "      <td>0</td>\n",
       "      <td>1582998</td>\n",
       "      <td>[0.09759521484375, -0.233642578125, -0.0789794...</td>\n",
       "      <td>65606</td>\n",
       "      <td>[0.1590409960065569, -0.22170182112809067, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>95617</td>\n",
       "      <td>5436174</td>\n",
       "      <td>20230101085031</td>\n",
       "      <td>0</td>\n",
       "      <td>5436174</td>\n",
       "      <td>[0.1181640625, -0.2105712890625, 0.00327110290...</td>\n",
       "      <td>95617</td>\n",
       "      <td>[0.13951278411032197, -0.20915239184872478, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16943195</th>\n",
       "      <td>26730</td>\n",
       "      <td>2466070</td>\n",
       "      <td>20230630235958</td>\n",
       "      <td>0</td>\n",
       "      <td>2466070</td>\n",
       "      <td>[0.1097412109375, -0.11407470703125, 0.0979614...</td>\n",
       "      <td>26730</td>\n",
       "      <td>[0.13095803925248442, -0.22063742048753415, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16943196</th>\n",
       "      <td>94142</td>\n",
       "      <td>380415</td>\n",
       "      <td>20230630235958</td>\n",
       "      <td>0</td>\n",
       "      <td>380415</td>\n",
       "      <td>[0.0293731689453125, -0.1512451171875, 0.22021...</td>\n",
       "      <td>94142</td>\n",
       "      <td>[0.13742323905702622, -0.22445696876162574, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16943197</th>\n",
       "      <td>60002</td>\n",
       "      <td>172743</td>\n",
       "      <td>20230630235958</td>\n",
       "      <td>0</td>\n",
       "      <td>172743</td>\n",
       "      <td>[0.121826171875, -0.1566162109375, 0.153442382...</td>\n",
       "      <td>60002</td>\n",
       "      <td>[0.13576889038085938, -0.19163131713867188, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16943198</th>\n",
       "      <td>79881</td>\n",
       "      <td>4836642</td>\n",
       "      <td>20230630235958</td>\n",
       "      <td>0</td>\n",
       "      <td>4836642</td>\n",
       "      <td>[0.162109375, -0.3369140625, 0.09149169921875,...</td>\n",
       "      <td>79881</td>\n",
       "      <td>[0.15100748504823594, -0.21996993962518002, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16943199</th>\n",
       "      <td>55653</td>\n",
       "      <td>4042368</td>\n",
       "      <td>20230630235959</td>\n",
       "      <td>0</td>\n",
       "      <td>4042368</td>\n",
       "      <td>[0.101806640625, -0.07940673828125, 0.17797851...</td>\n",
       "      <td>55653</td>\n",
       "      <td>[0.1238953676173296, -0.195694090828063, 0.081...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16943200 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          source_node  destination_node       timestamp  edge_label  item_id  \\\n",
       "0               50947           3460233  20230101054209           0  3460233   \n",
       "1               50947           1582998  20230101062342           0  1582998   \n",
       "2               24218           1582998  20230101065337           0  1582998   \n",
       "3               65606           1582998  20230101072700           0  1582998   \n",
       "4               95617           5436174  20230101085031           0  5436174   \n",
       "...               ...               ...             ...         ...      ...   \n",
       "16943195        26730           2466070  20230630235958           0  2466070   \n",
       "16943196        94142            380415  20230630235958           0   380415   \n",
       "16943197        60002            172743  20230630235958           0   172743   \n",
       "16943198        79881           4836642  20230630235958           0  4836642   \n",
       "16943199        55653           4042368  20230630235959           0  4042368   \n",
       "\n",
       "                                                 embeddings  user_id  \\\n",
       "0         [0.274658203125, -0.10504150390625, 0.07116699...    50947   \n",
       "1         [0.09759521484375, -0.233642578125, -0.0789794...    50947   \n",
       "2         [0.09759521484375, -0.233642578125, -0.0789794...    24218   \n",
       "3         [0.09759521484375, -0.233642578125, -0.0789794...    65606   \n",
       "4         [0.1181640625, -0.2105712890625, 0.00327110290...    95617   \n",
       "...                                                     ...      ...   \n",
       "16943195  [0.1097412109375, -0.11407470703125, 0.0979614...    26730   \n",
       "16943196  [0.0293731689453125, -0.1512451171875, 0.22021...    94142   \n",
       "16943197  [0.121826171875, -0.1566162109375, 0.153442382...    60002   \n",
       "16943198  [0.162109375, -0.3369140625, 0.09149169921875,...    79881   \n",
       "16943199  [0.101806640625, -0.07940673828125, 0.17797851...    55653   \n",
       "\n",
       "                                             user_embedding  \n",
       "0         [0.15769888380192854, -0.22164885611644441, 0....  \n",
       "1         [0.15769888380192854, -0.22164885611644441, 0....  \n",
       "2         [0.13439939289449532, -0.2052124593859521, 0.0...  \n",
       "3         [0.1590409960065569, -0.22170182112809067, 0.0...  \n",
       "4         [0.13951278411032197, -0.20915239184872478, 0....  \n",
       "...                                                     ...  \n",
       "16943195  [0.13095803925248442, -0.22063742048753415, 0....  \n",
       "16943196  [0.13742323905702622, -0.22445696876162574, 0....  \n",
       "16943197  [0.13576889038085938, -0.19163131713867188, 0....  \n",
       "16943198  [0.15100748504823594, -0.21996993962518002, 0....  \n",
       "16943199  [0.1238953676173296, -0.195694090828063, 0.081...  \n",
       "\n",
       "[16943200 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_node</th>\n",
       "      <th>destination_node</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>edge_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12248</td>\n",
       "      <td>1349</td>\n",
       "      <td>20230101024321</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50947</td>\n",
       "      <td>3044497</td>\n",
       "      <td>20230101024954</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24218</td>\n",
       "      <td>2347863</td>\n",
       "      <td>20230101035202</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13743</td>\n",
       "      <td>1349</td>\n",
       "      <td>20230101051655</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50947</td>\n",
       "      <td>1349</td>\n",
       "      <td>20230101053502</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22131393</th>\n",
       "      <td>79881</td>\n",
       "      <td>4836642</td>\n",
       "      <td>20230630235958</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22131394</th>\n",
       "      <td>103308</td>\n",
       "      <td>47287</td>\n",
       "      <td>20230630235959</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22131395</th>\n",
       "      <td>87720</td>\n",
       "      <td>1073032</td>\n",
       "      <td>20230630235959</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22131396</th>\n",
       "      <td>27780</td>\n",
       "      <td>1077586</td>\n",
       "      <td>20230630235959</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22131397</th>\n",
       "      <td>55653</td>\n",
       "      <td>4042368</td>\n",
       "      <td>20230630235959</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22131398 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          source_node  destination_node       timestamp  edge_label\n",
       "0               12248              1349  20230101024321           0\n",
       "1               50947           3044497  20230101024954           0\n",
       "2               24218           2347863  20230101035202           0\n",
       "3               13743              1349  20230101051655           0\n",
       "4               50947              1349  20230101053502           0\n",
       "...               ...               ...             ...         ...\n",
       "22131393        79881           4836642  20230630235958           0\n",
       "22131394       103308             47287  20230630235959           0\n",
       "22131395        87720           1073032  20230630235959           0\n",
       "22131396        27780           1077586  20230630235959           0\n",
       "22131397        55653           4042368  20230630235959           0\n",
       "\n",
       "[22131398 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 35444:\n",
      "Number of liked posts: 299\n",
      "\n",
      "User embedding (first 20 values):\n",
      "[ 0.14168766 -0.21814904  0.07155541  0.01467382  0.12980633 -0.12021306\n",
      " -0.0813206   0.21462916 -0.01470117  0.00618066 -0.03683629  0.23589965\n",
      " -0.02831887 -0.08918404 -0.12999587 -0.03339204 -0.15233823  0.11898526\n",
      "  0.00622435  0.01602863]\n",
      "\n",
      "Liked posts embeddings (first 3 posts, first 20 values):\n",
      "Post 0: [ 0.18701172 -0.17150879 -0.0092392   0.06329346  0.05584717 -0.31567383\n",
      " -0.02438354  0.3347168   0.01186371 -0.04571533 -0.03271484  0.15649414\n",
      " -0.05749512 -0.08392334 -0.29541016 -0.09289551 -0.1776123   0.11749268\n",
      "  0.02186584 -0.03771973]\n",
      "Post 1: [ 0.10620117 -0.22729492 -0.01808167  0.00167561  0.1484375  -0.10430908\n",
      " -0.17626953  0.08087158 -0.05752563 -0.0049057   0.03503418  0.2097168\n",
      "  0.10949707 -0.2244873  -0.21923828 -0.1116333  -0.20629883  0.11004639\n",
      "  0.04299927  0.02284241]\n",
      "Post 2: [ 0.08703613 -0.2019043  -0.01100922  0.09820557  0.14025879 -0.13244629\n",
      " -0.13562012  0.10418701  0.09564209  0.14099121 -0.00315285  0.35498047\n",
      " -0.07275391 -0.0329895  -0.13476562  0.03875732 -0.13354492  0.12402344\n",
      "  0.01992798  0.01195526]\n",
      "Post 3: [ 0.0463562  -0.19262695  0.04901123  0.10125732  0.12182617 -0.20800781\n",
      " -0.23034668  0.19116211 -0.10253906 -0.08349609 -0.04421997  0.32885742\n",
      " -0.10778809  0.0209198  -0.13366699 -0.02885437 -0.24853516  0.09686279\n",
      " -0.01096344  0.03265381]\n",
      "Post 4: [ 0.13269043 -0.28540039  0.14038086  0.02210999  0.2265625  -0.14404297\n",
      " -0.14135742  0.20373535 -0.07342529 -0.09173584 -0.18579102  0.21081543\n",
      " -0.01931763 -0.04058838 -0.22167969  0.04147339 -0.08660889  0.12512207\n",
      " -0.040802   -0.01271057]\n",
      "Post 5: [ 0.32666016 -0.11431885  0.10424805 -0.11749268 -0.06008911 -0.01010895\n",
      " -0.12658691  0.23925781  0.04846191  0.14294434 -0.08886719  0.30371094\n",
      "  0.01898193  0.05032349 -0.02690125 -0.02360535 -0.10656738  0.13647461\n",
      "  0.08837891 -0.12133789]\n",
      "Post 6: [ 0.21264648 -0.10089111  0.07373047 -0.00354767  0.07849121 -0.01301575\n",
      " -0.03323364  0.23010254 -0.00699997 -0.05551147  0.05377197  0.26245117\n",
      " -0.01424408 -0.00611496 -0.17077637 -0.09448242 -0.20117188  0.09191895\n",
      "  0.0317688  -0.01100922]\n",
      "Post 7: [ 0.09429932 -0.26269531  0.14953613  0.10076904  0.23474121 -0.15600586\n",
      " -0.09863281  0.203125   -0.03710938 -0.03842163  0.00307274  0.32250977\n",
      " -0.01303101 -0.23986816 -0.18994141  0.06536865 -0.1348877   0.11584473\n",
      " -0.09088135  0.01521301]\n",
      "Post 8: [ 0.15966797 -0.29052734  0.08190918  0.13623047  0.03399658 -0.0607605\n",
      " -0.08538818  0.24584961 -0.03414917  0.15075684 -0.03869629  0.25952148\n",
      "  0.01651001 -0.07183838 -0.15454102 -0.03530884 -0.12213135  0.02929688\n",
      "  0.20788574 -0.07702637]\n",
      "\n",
      "Verification - are user embeddings the average of liked posts?\n",
      "Max difference: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Pick a random user_id to examine\n",
    "user_id = final_df['user_id'].iloc[21]\n",
    "\n",
    "# Get their embedding\n",
    "user_emb = final_df[final_df['user_id'] == user_id]['user_embedding'].iloc[0]\n",
    "\n",
    "# Get all posts this user liked\n",
    "liked_posts = final_df[final_df['user_id'] == user_id]['destination_node'].values\n",
    "\n",
    "# Get embeddings for these posts\n",
    "liked_post_embeddings = post_embeddings_df[post_embeddings_df['item_id'].isin(liked_posts)]['embeddings'].values\n",
    "\n",
    "print(f\"User {user_id}:\")\n",
    "print(f\"Number of liked posts: {len(liked_posts)}\")\n",
    "print(f\"\\nUser embedding (first 20 values):\\n{user_emb[:20]}\")\n",
    "print(f\"\\nLiked posts embeddings (first 3 posts, first 20 values):\")\n",
    "for i, emb in enumerate(liked_post_embeddings[:9]):\n",
    "    print(f\"Post {i}: {emb[:20]}\")\n",
    "\n",
    "# Verify that user embedding is indeed the average\n",
    "avg_liked_embeddings = np.mean(liked_post_embeddings, axis=0)\n",
    "print(f\"\\nVerification - are user embeddings the average of liked posts?\")\n",
    "print(f\"Max difference: {np.max(np.abs(user_emb - avg_liked_embeddings))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Dataset and Dataloader and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserPostDataset(Dataset):\n",
    "    def __init__(self, df, negative_samples=1):\n",
    "        self.df = df\n",
    "        self.negative_samples = negative_samples\n",
    "        # Precompute user's positive posts for faster lookup\n",
    "        self.user_positives = {\n",
    "            user: set(group['destination_node'].values) \n",
    "            for user, group in df.groupby('source_node')\n",
    "        }\n",
    "        self.all_posts = df['destination_node'].unique()\n",
    "        # Calculate total length including negative samples\n",
    "        self.length = len(df) * (self.negative_samples + 1)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.length  # Return integer length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        interaction_idx = idx // (self.negative_samples + 1)\n",
    "        is_positive = idx % (self.negative_samples + 1) == 0\n",
    "        \n",
    "        row = self.df.iloc[interaction_idx]\n",
    "        user_id = row['source_node']\n",
    "        \n",
    "        if is_positive:\n",
    "            post_emb = row['embeddings']\n",
    "            user_emb = row['user_embedding']\n",
    "        else:\n",
    "            # Simple random sampling without checking\n",
    "            neg_post_idx = np.random.choice(len(self.df))\n",
    "            neg_post = self.df.iloc[neg_post_idx]\n",
    "            post_emb = neg_post['embeddings']\n",
    "            user_emb = row['user_embedding']\n",
    "        \n",
    "        return (\n",
    "            torch.tensor(user_emb, dtype=torch.float32),\n",
    "            torch.tensor(post_emb, dtype=torch.float32),\n",
    "            torch.tensor(1.0 if is_positive else 0.0, dtype=torch.float32)\n",
    "        )\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_df, val_df = train_test_split(final_df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = UserPostDataset(train_df)\n",
    "val_dataset = UserPostDataset(val_df)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1024, shuffle=False, num_workers=4)\n",
    "\n",
    "embedding_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleTwoTowerModel(embedding_dim).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Training loop with gradient norm monitoring\n",
    "\n",
    "# for batch_idx, (user_features, post_features, labels) in enumerate(tqdm(train_loader)):\n",
    "#     user_features = user_features.to(device)\n",
    "#     post_features = post_features.to(device)\n",
    "#     labels = labels.to(device)\n",
    "    \n",
    "#     optimizer.zero_grad()\n",
    "#     user_emb, post_emb = model(user_features, post_features)\n",
    "#     scores = torch.sum(user_emb * post_emb, dim=1)\n",
    "#     loss = criterion(scores, labels)\n",
    "    \n",
    "#     loss.backward()\n",
    "    \n",
    "#     # Monitor gradients\n",
    "#     total_norm = 0\n",
    "#     for p in model.parameters():\n",
    "#         if p.grad is not None:\n",
    "#             param_norm = p.grad.data.norm(2)\n",
    "#             total_norm += param_norm.item() ** 2\n",
    "#     total_norm = total_norm ** 0.5\n",
    "    \n",
    "#     optimizer.step()\n",
    "    \n",
    "#     if batch_idx % 3000 == 0:\n",
    "#         print(f\"Batch {batch_idx} statistics:\")\n",
    "#         print(f\"  Loss: {loss.item():.4f}\")\n",
    "#         print(f\"  Gradient norm: {total_norm:.4f}\")\n",
    "#         print(f\"  Score range: [{scores.min().item():.4f}, {scores.max().item():.4f}]\")\n",
    "#         print(f\"  Prediction mean: {torch.sigmoid(scores).mean().item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Save the model. Comment this out if you don't want to save the model to proceed to just loading the model.\n",
    "# Save model\n",
    "# torch.save({\n",
    "#     'model_state_dict': model.state_dict(),\n",
    "#     'optimizer_state_dict': optimizer.state_dict(),\n",
    "# }, 'data/two_tower_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32846/119995845.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('data/two_tower_model.pt')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User: https://bsky.app/profile/did:plc:jiymvt4mz2vyerrhe7o7sgdn\n",
      "Number of posts user actually liked: 467\n",
      "\n",
      "Top 5 recommended posts:\n",
      "\n",
      "Post 1: https://bsky.app/profile/did:plc:p4474re3x6buxlzdeampcwqn/post/3jxnsga3xkf2r\n",
      "Score: 0.992, Not liked\n",
      "Cosine Similarity: 0.992\n",
      "\n",
      "Post 2: https://bsky.app/profile/did:plc:oe52hqd375jatrxjdugzjnap/post/3jz5ciwxv3m2u\n",
      "Score: 0.991, Not liked\n",
      "Cosine Similarity: 0.991\n",
      "\n",
      "Post 3: https://bsky.app/profile/did:plc:wd5brnxbsbcexgmvnkenkfm3/post/3jxn7rjrwfk2t\n",
      "Score: 0.991, Not liked\n",
      "Cosine Similarity: 0.991\n",
      "\n",
      "Post 4: https://bsky.app/profile/did:plc:e2gj6s2ljmyen7msreqed536/post/3jwzv3aup6t2g\n",
      "Score: 0.991, Not liked\n",
      "Cosine Similarity: 0.991\n",
      "\n",
      "Post 5: https://bsky.app/profile/did:plc:tbl752vbbw3buafdqzc4d7oz/post/3jwhyhnrj4p2m\n",
      "Score: 0.990, Not liked\n",
      "Cosine Similarity: 0.990\n",
      "\n",
      "User: https://bsky.app/profile/did:plc:53ufa4fnn5w5jdtwnd6747th\n",
      "Number of posts user actually liked: 23\n",
      "\n",
      "Top 5 recommended posts:\n",
      "\n",
      "Post 1: https://bsky.app/profile/did:plc:txandrhc7afdozk6a2itgltm/post/3juqidxjxsl2z\n",
      "Score: 0.993, Not liked\n",
      "Cosine Similarity: 0.993\n",
      "\n",
      "Post 2: https://bsky.app/profile/did:plc:ob74rl7gg3tzwf54fxy22bdl/post/3jvyqip7w5s2m\n",
      "Score: 0.992, Not liked\n",
      "Cosine Similarity: 0.992\n",
      "\n",
      "Post 3: https://bsky.app/profile/did:plc:uqzpqmrjnptsxezjx4xuh2mn/post/3jwk45yditd2q\n",
      "Score: 0.992, Not liked\n",
      "Cosine Similarity: 0.992\n",
      "\n",
      "Post 4: https://bsky.app/profile/did:plc:gi6tz7qkbkqfz5e5djuacd6l/post/3jwwxtj73ot2e\n",
      "Score: 0.991, Not liked\n",
      "Cosine Similarity: 0.991\n",
      "\n",
      "Post 5: https://bsky.app/profile/did:plc:o424ck44uubd3lnk4ztzbq7a/post/3jwkftohdps2d\n",
      "Score: 0.990, Not liked\n",
      "Cosine Similarity: 0.990\n",
      "\n",
      "User: https://bsky.app/profile/did:plc:jsqi5pvpxp4doyk4wf2ylmdj\n",
      "Number of posts user actually liked: 5\n",
      "\n",
      "Top 5 recommended posts:\n",
      "\n",
      "Post 1: https://bsky.app/profile/did:plc:57vlzz2egy6eqr4nksacmbht/post/3jynaztnyno2u\n",
      "Score: 0.911, Not liked\n",
      "Cosine Similarity: 0.911\n",
      "\n",
      "Post 2: https://bsky.app/profile/did:plc:qrllvid7s54k4hnwtqxwetrf/post/3jwvvyvblpk2z\n",
      "Score: 0.910, Not liked\n",
      "Cosine Similarity: 0.910\n",
      "\n",
      "Post 3: https://bsky.app/profile/did:plc:umpsiyampiq3bpgce7kigydz/post/3juhxdpirrk23\n",
      "Score: 0.904, Not liked\n",
      "Cosine Similarity: 0.904\n",
      "\n",
      "Post 4: https://bsky.app/profile/did:plc:f3vzol6kqt2zps3zgcssfhhl/post/3jxp7qc5xhl2e\n",
      "Score: 0.904, Not liked\n",
      "Cosine Similarity: 0.904\n",
      "\n",
      "Post 5: https://bsky.app/profile/did:plc:oixkjhvqhly2jwihblmd2qba/post/3jumxp73jhm2c\n",
      "Score: 0.904, Not liked\n",
      "Cosine Similarity: 0.904\n",
      "\n",
      "User: https://bsky.app/profile/did:plc:ievijhmv33dpvanyn7xhsqsc\n",
      "Number of posts user actually liked: 13\n",
      "\n",
      "Top 5 recommended posts:\n",
      "\n",
      "Post 1: https://bsky.app/profile/did:plc:zsdhduo2ahpdhfa73uynnbf2/post/3jxuvqbh6ye2n\n",
      "Score: 0.993, Not liked\n",
      "Cosine Similarity: 0.993\n",
      "\n",
      "Post 2: https://bsky.app/profile/did:plc:k733ho42hqkv44xzeehmmqvq/post/3juqmkhuf6h2h\n",
      "Score: 0.992, Not liked\n",
      "Cosine Similarity: 0.992\n",
      "\n",
      "Post 3: https://bsky.app/profile/did:plc:t7viwd7q7ck44a6apmifkbpp/post/3jzcl4dirmx2r\n",
      "Score: 0.991, Not liked\n",
      "Cosine Similarity: 0.991\n",
      "\n",
      "Post 4: https://bsky.app/profile/did:plc:yp4knr3s4f6nji2fsywkoaoh/post/3jw6a7haxt225\n",
      "Score: 0.989, Not liked\n",
      "Cosine Similarity: 0.989\n",
      "\n",
      "Post 5: https://bsky.app/profile/did:plc:ubm3op4bzhwuugu5wkcxiquv/post/3jsrlke7vo222\n",
      "Score: 0.988, Not liked\n",
      "Cosine Similarity: 0.988\n",
      "\n",
      "User: https://bsky.app/profile/did:plc:73xtydydylhwoeq2jzg6xhu5\n",
      "Number of posts user actually liked: 12\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model = SimpleTwoTowerModel(embedding_dim).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "checkpoint = torch.load('data/two_tower_model.pt')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "# 2. Test the model with some examples\n",
    "model.eval()  # Set to evaluation mode\n",
    "\n",
    "# Load mappings\n",
    "with open('data/user_mapping.pkl', 'rb') as f:\n",
    "    user_mapping = pickle.load(f)\n",
    "reverse_user_mapping = {v: k for k, v in user_mapping.items()}\n",
    "\n",
    "with open('data/post_mapping.pkl', 'rb') as f:\n",
    "    post_mapping = pickle.load(f)\n",
    "reverse_post_mapping = {v: k for k, v in post_mapping.items()}\n",
    "\n",
    "def get_post_info(post_id):\n",
    "    \"\"\"Extract post info from mapping key\"\"\"\n",
    "    full_id = reverse_post_mapping.get(post_id)\n",
    "    if full_id:\n",
    "        did, post_ref = full_id.split('_')\n",
    "        return did, post_ref\n",
    "    return None, None\n",
    "\n",
    "def get_recommendations(user_id, n_recommendations=5):\n",
    "    # Get user's embedding\n",
    "    user_data = final_df[final_df['source_node'] == user_id].iloc[0]\n",
    "    user_features = torch.tensor(user_data['user_embedding'], dtype=torch.float32).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Get all post embeddings\n",
    "    all_posts = final_df[['destination_node', 'embeddings']].drop_duplicates('destination_node')\n",
    "    post_features = torch.tensor(np.stack(all_posts['embeddings']), dtype=torch.float32).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        user_emb, post_emb = model(user_features, post_features)\n",
    "        scores = torch.sum(user_emb * post_emb, dim=1)\n",
    "        \n",
    "    # Get top K recommendations\n",
    "    top_k_scores, top_k_indices = torch.topk(scores, k=n_recommendations)\n",
    "    recommendations = all_posts.iloc[top_k_indices.cpu().numpy()]\n",
    "    \n",
    "    return (\n",
    "        recommendations['destination_node'].tolist(), \n",
    "        top_k_scores.cpu().numpy(),\n",
    "        user_emb.cpu().numpy(),\n",
    "        post_emb[top_k_indices].cpu().numpy(),\n",
    "        user_features.cpu().numpy(),\n",
    "        torch.tensor(np.stack(recommendations['embeddings'])).numpy()\n",
    "    )\n",
    "\n",
    "# Test for a few users\n",
    "test_users = final_df['source_node'].unique()[1000:1003]\n",
    "\n",
    "for user_id in test_users:\n",
    "    user_did = reverse_user_mapping.get(user_id)\n",
    "    print(f\"\\nUser: https://bsky.app/profile/{user_did}\")\n",
    "    \n",
    "    # Get user's actual liked posts\n",
    "    liked_posts = set(final_df[final_df['source_node'] == user_id]['destination_node'])\n",
    "    print(f\"Number of posts user actually liked: {len(liked_posts)}\")\n",
    "    \n",
    "    # Get recommendations and embeddings\n",
    "    rec_posts, rec_scores, user_emb, post_embs, orig_user_feat, orig_post_feats = get_recommendations(user_id, n_recommendations=5)\n",
    "    \n",
    "    print(\"\\nTop 5 recommended posts:\")\n",
    "    for idx, (post_id, score, post_emb, orig_post_feat) in enumerate(zip(rec_posts, rec_scores, post_embs, orig_post_feats)):\n",
    "        status = \"Actually liked\" if post_id in liked_posts else \"Not liked\"\n",
    "        \n",
    "        # Get post info\n",
    "        author_did, post_ref = get_post_info(post_id)\n",
    "        if author_did and post_ref:\n",
    "            print(f\"\\nPost {idx+1}: https://bsky.app/profile/{author_did}/post/{post_ref}\")\n",
    "        else:\n",
    "            print(f\"\\nPost {idx+1} ID {post_id} not found in mapping\")\n",
    "            \n",
    "        print(f\"Score: {score:.3f}, {status}\")\n",
    "        \n",
    "        # Calculate and print similarity details\n",
    "        cosine_sim = np.dot(user_emb[0], post_emb) / (np.linalg.norm(user_emb[0]) * np.linalg.norm(post_emb))\n",
    "        print(f\"Cosine Similarity: {cosine_sim:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating recall@k on validation set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78322/78322 [44:59<00:00, 29.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@5: 0.000\n",
      "Recall@10: 0.000\n",
      "Recall@20: 0.000\n",
      "Recall@50: 0.001\n",
      "\n",
      "Calculating recall@k using direct embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 468/78322 [1:08:46<190:39:59,  8.82s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 78\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m avg_recalls\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCalculating recall@k using direct embeddings...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 78\u001b[0m direct_recalls \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_direct_recall_at_k\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, recall \u001b[38;5;129;01min\u001b[39;00m direct_recalls\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDirect Recall@\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecall\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[13], line 60\u001b[0m, in \u001b[0;36mcalculate_direct_recall_at_k\u001b[0;34m(test_df, k_values)\u001b[0m\n\u001b[1;32m     57\u001b[0m all_posts \u001b[38;5;241m=\u001b[39m test_df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdestination_node\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mdrop_duplicates(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdestination_node\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Calculate similarities\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m similarities \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     61\u001b[0m     np\u001b[38;5;241m.\u001b[39mdot(post_emb, user_embedding) \u001b[38;5;241m/\u001b[39m (np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(post_emb) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(user_embedding))\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m post_emb \u001b[38;5;129;01min\u001b[39;00m all_posts[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     63\u001b[0m ]\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# Get top k recommendations\u001b[39;00m\n\u001b[1;32m     66\u001b[0m top_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(similarities)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mmax\u001b[39m(k_values):][::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "Cell \u001b[0;32mIn[13], line 61\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     57\u001b[0m all_posts \u001b[38;5;241m=\u001b[39m test_df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdestination_node\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mdrop_duplicates(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdestination_node\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Calculate similarities\u001b[39;00m\n\u001b[1;32m     60\u001b[0m similarities \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m---> 61\u001b[0m     np\u001b[38;5;241m.\u001b[39mdot(post_emb, user_embedding) \u001b[38;5;241m/\u001b[39m (np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(post_emb) \u001b[38;5;241m*\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_embedding\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m post_emb \u001b[38;5;129;01min\u001b[39;00m all_posts[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     63\u001b[0m ]\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# Get top k recommendations\u001b[39;00m\n\u001b[1;32m     66\u001b[0m top_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(similarities)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mmax\u001b[39m(k_values):][::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/Projects/Bluesky-GraphRec/.venv/lib/python3.10/site-packages/numpy/linalg/_linalg.py:2571\u001b[0m, in \u001b[0;36m_norm_dispatcher\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m   2567\u001b[0m     result \u001b[38;5;241m=\u001b[39m op(svd(y, compute_uv\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   2568\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m-> 2571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_norm_dispatcher\u001b[39m(x, \u001b[38;5;28mord\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   2572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (x,)\n\u001b[1;32m   2575\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_norm_dispatcher)\n\u001b[1;32m   2576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnorm\u001b[39m(x, \u001b[38;5;28mord\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def calculate_recall_at_k(model, test_df, k_values=[5, 10, 20, 50]):\n",
    "    \"\"\"Calculate recall@k for multiple k values\"\"\"\n",
    "    model.eval()\n",
    "    recalls = {k: [] for k in k_values}\n",
    "    \n",
    "    # Get unique users\n",
    "    unique_users = test_df['source_node'].unique()\n",
    "    \n",
    "    # Get all posts for recommendations\n",
    "    all_posts = test_df[['destination_node', 'embeddings']].drop_duplicates('destination_node')\n",
    "    all_post_features = torch.tensor(np.stack(all_posts['embeddings']), dtype=torch.float32).to(device)\n",
    "    \n",
    "    for user_id in tqdm(unique_users):\n",
    "        # Get user's actual liked posts\n",
    "        actual_likes = set(test_df[test_df['source_node'] == user_id]['destination_node'])\n",
    "        \n",
    "        # Get user embedding\n",
    "        user_data = test_df[test_df['source_node'] == user_id].iloc[0]\n",
    "        user_features = torch.tensor(user_data['user_embedding'], dtype=torch.float32).unsqueeze(0).to(device)\n",
    "        \n",
    "        # Get recommendations\n",
    "        with torch.no_grad():\n",
    "            user_emb, post_emb = model(user_features, all_post_features)\n",
    "            scores = torch.sum(user_emb * post_emb, dim=1)\n",
    "            \n",
    "        # Calculate recall@k for each k\n",
    "        _, top_indices = torch.topk(scores, k=max(k_values))\n",
    "        recommended_posts = all_posts.iloc[top_indices.cpu().numpy()]['destination_node'].tolist()\n",
    "        \n",
    "        for k in k_values:\n",
    "            recommended_at_k = set(recommended_posts[:k])\n",
    "            recall = len(recommended_at_k.intersection(actual_likes)) / len(actual_likes)\n",
    "            recalls[k].append(recall)\n",
    "    \n",
    "    # Calculate average recall for each k\n",
    "    avg_recalls = {k: np.mean(values) for k, values in recalls.items()}\n",
    "    return avg_recalls\n",
    "\n",
    "# Calculate recall@k for both validation set\n",
    "print(\"Calculating recall@k on validation set...\")\n",
    "val_recalls = calculate_recall_at_k(model, val_df)\n",
    "for k, recall in val_recalls.items():\n",
    "    print(f\"Recall@{k}: {recall:.3f}\")\n",
    "\n",
    "# Also calculate recall@k using direct embeddings for comparison\n",
    "def calculate_direct_recall_at_k(test_df, k_values=[5, 10, 20, 50]):\n",
    "    \"\"\"Calculate recall@k using original embeddings directly\"\"\"\n",
    "    recalls = {k: [] for k in k_values}\n",
    "    unique_users = test_df['source_node'].unique()\n",
    "    \n",
    "    for user_id in tqdm(unique_users):\n",
    "        # Get user's actual liked posts\n",
    "        actual_likes = set(test_df[test_df['source_node'] == user_id]['destination_node'])\n",
    "        \n",
    "        # Get user embedding and all posts\n",
    "        user_embedding = test_df[test_df['source_node'] == user_id]['user_embedding'].iloc[0]\n",
    "        all_posts = test_df[['destination_node', 'embeddings']].drop_duplicates('destination_node')\n",
    "        \n",
    "        # Calculate similarities\n",
    "        similarities = [\n",
    "            np.dot(post_emb, user_embedding) / (np.linalg.norm(post_emb) * np.linalg.norm(user_embedding))\n",
    "            for post_emb in all_posts['embeddings']\n",
    "        ]\n",
    "        \n",
    "        # Get top k recommendations\n",
    "        top_indices = np.argsort(similarities)[-max(k_values):][::-1]\n",
    "        recommended_posts = all_posts.iloc[top_indices]['destination_node'].tolist()\n",
    "        \n",
    "        for k in k_values:\n",
    "            recommended_at_k = set(recommended_posts[:k])\n",
    "            recall = len(recommended_at_k.intersection(actual_likes)) / len(actual_likes)\n",
    "            recalls[k].append(recall)\n",
    "    \n",
    "    avg_recalls = {k: np.mean(values) for k, values in recalls.items()}\n",
    "    return avg_recalls\n",
    "\n",
    "print(\"\\nCalculating recall@k using direct embeddings...\")\n",
    "direct_recalls = calculate_direct_recall_at_k(val_df)\n",
    "for k, recall in direct_recalls.items():\n",
    "    print(f\"Direct Recall@{k}: {recall:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_node</th>\n",
       "      <th>destination_node</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>edge_label</th>\n",
       "      <th>item_id</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50947</td>\n",
       "      <td>3460233</td>\n",
       "      <td>20230101054209</td>\n",
       "      <td>0</td>\n",
       "      <td>3460233</td>\n",
       "      <td>[0.274658203125, -0.10504150390625, 0.07116699...</td>\n",
       "      <td>50947</td>\n",
       "      <td>[0.15769888380192854, -0.22164885611644441, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50947</td>\n",
       "      <td>1582998</td>\n",
       "      <td>20230101062342</td>\n",
       "      <td>0</td>\n",
       "      <td>1582998</td>\n",
       "      <td>[0.09759521484375, -0.233642578125, -0.0789794...</td>\n",
       "      <td>50947</td>\n",
       "      <td>[0.15769888380192854, -0.22164885611644441, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24218</td>\n",
       "      <td>1582998</td>\n",
       "      <td>20230101065337</td>\n",
       "      <td>0</td>\n",
       "      <td>1582998</td>\n",
       "      <td>[0.09759521484375, -0.233642578125, -0.0789794...</td>\n",
       "      <td>24218</td>\n",
       "      <td>[0.13439939289449532, -0.2052124593859521, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65606</td>\n",
       "      <td>1582998</td>\n",
       "      <td>20230101072700</td>\n",
       "      <td>0</td>\n",
       "      <td>1582998</td>\n",
       "      <td>[0.09759521484375, -0.233642578125, -0.0789794...</td>\n",
       "      <td>65606</td>\n",
       "      <td>[0.1590409960065569, -0.22170182112809067, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>95617</td>\n",
       "      <td>5436174</td>\n",
       "      <td>20230101085031</td>\n",
       "      <td>0</td>\n",
       "      <td>5436174</td>\n",
       "      <td>[0.1181640625, -0.2105712890625, 0.00327110290...</td>\n",
       "      <td>95617</td>\n",
       "      <td>[0.13951278411032197, -0.20915239184872478, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16943195</th>\n",
       "      <td>26730</td>\n",
       "      <td>2466070</td>\n",
       "      <td>20230630235958</td>\n",
       "      <td>0</td>\n",
       "      <td>2466070</td>\n",
       "      <td>[0.1097412109375, -0.11407470703125, 0.0979614...</td>\n",
       "      <td>26730</td>\n",
       "      <td>[0.13095803925248442, -0.22063742048753415, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16943196</th>\n",
       "      <td>94142</td>\n",
       "      <td>380415</td>\n",
       "      <td>20230630235958</td>\n",
       "      <td>0</td>\n",
       "      <td>380415</td>\n",
       "      <td>[0.0293731689453125, -0.1512451171875, 0.22021...</td>\n",
       "      <td>94142</td>\n",
       "      <td>[0.13742323905702622, -0.22445696876162574, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16943197</th>\n",
       "      <td>60002</td>\n",
       "      <td>172743</td>\n",
       "      <td>20230630235958</td>\n",
       "      <td>0</td>\n",
       "      <td>172743</td>\n",
       "      <td>[0.121826171875, -0.1566162109375, 0.153442382...</td>\n",
       "      <td>60002</td>\n",
       "      <td>[0.13576889038085938, -0.19163131713867188, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16943198</th>\n",
       "      <td>79881</td>\n",
       "      <td>4836642</td>\n",
       "      <td>20230630235958</td>\n",
       "      <td>0</td>\n",
       "      <td>4836642</td>\n",
       "      <td>[0.162109375, -0.3369140625, 0.09149169921875,...</td>\n",
       "      <td>79881</td>\n",
       "      <td>[0.15100748504823594, -0.21996993962518002, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16943199</th>\n",
       "      <td>55653</td>\n",
       "      <td>4042368</td>\n",
       "      <td>20230630235959</td>\n",
       "      <td>0</td>\n",
       "      <td>4042368</td>\n",
       "      <td>[0.101806640625, -0.07940673828125, 0.17797851...</td>\n",
       "      <td>55653</td>\n",
       "      <td>[0.1238953676173296, -0.195694090828063, 0.081...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16943200 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          source_node  destination_node       timestamp  edge_label  item_id  \\\n",
       "0               50947           3460233  20230101054209           0  3460233   \n",
       "1               50947           1582998  20230101062342           0  1582998   \n",
       "2               24218           1582998  20230101065337           0  1582998   \n",
       "3               65606           1582998  20230101072700           0  1582998   \n",
       "4               95617           5436174  20230101085031           0  5436174   \n",
       "...               ...               ...             ...         ...      ...   \n",
       "16943195        26730           2466070  20230630235958           0  2466070   \n",
       "16943196        94142            380415  20230630235958           0   380415   \n",
       "16943197        60002            172743  20230630235958           0   172743   \n",
       "16943198        79881           4836642  20230630235958           0  4836642   \n",
       "16943199        55653           4042368  20230630235959           0  4042368   \n",
       "\n",
       "                                                 embeddings  user_id  \\\n",
       "0         [0.274658203125, -0.10504150390625, 0.07116699...    50947   \n",
       "1         [0.09759521484375, -0.233642578125, -0.0789794...    50947   \n",
       "2         [0.09759521484375, -0.233642578125, -0.0789794...    24218   \n",
       "3         [0.09759521484375, -0.233642578125, -0.0789794...    65606   \n",
       "4         [0.1181640625, -0.2105712890625, 0.00327110290...    95617   \n",
       "...                                                     ...      ...   \n",
       "16943195  [0.1097412109375, -0.11407470703125, 0.0979614...    26730   \n",
       "16943196  [0.0293731689453125, -0.1512451171875, 0.22021...    94142   \n",
       "16943197  [0.121826171875, -0.1566162109375, 0.153442382...    60002   \n",
       "16943198  [0.162109375, -0.3369140625, 0.09149169921875,...    79881   \n",
       "16943199  [0.101806640625, -0.07940673828125, 0.17797851...    55653   \n",
       "\n",
       "                                             user_embedding  \n",
       "0         [0.15769888380192854, -0.22164885611644441, 0....  \n",
       "1         [0.15769888380192854, -0.22164885611644441, 0....  \n",
       "2         [0.13439939289449532, -0.2052124593859521, 0.0...  \n",
       "3         [0.1590409960065569, -0.22170182112809067, 0.0...  \n",
       "4         [0.13951278411032197, -0.20915239184872478, 0....  \n",
       "...                                                     ...  \n",
       "16943195  [0.13095803925248442, -0.22063742048753415, 0....  \n",
       "16943196  [0.13742323905702622, -0.22445696876162574, 0....  \n",
       "16943197  [0.13576889038085938, -0.19163131713867188, 0....  \n",
       "16943198  [0.15100748504823594, -0.21996993962518002, 0....  \n",
       "16943199  [0.1238953676173296, -0.195694090828063, 0.081...  \n",
       "\n",
       "[16943200 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User: https://bsky.app/profile/did:plc:jiymvt4mz2vyerrhe7o7sgdn\n",
      "\n",
      "User's 5 Most Recent Likes:\n",
      "Post: https://bsky.app/profile/did:plc:33ihf27ze66oz3plaxucn47t/post/3jyvcdfbvuc2q\n",
      "Timestamp: 20230624061811\n",
      "---\n",
      "Post: https://bsky.app/profile/did:plc:7gasecytjqmgvoptx6ypyhvo/post/3jybv5iftgk25\n",
      "Timestamp: 20230618023235\n",
      "---\n",
      "Post: https://bsky.app/profile/did:plc:hwspbpfumiqyqzfeik7vilbu/post/3jxy2hdnhp72s\n",
      "Timestamp: 20230612152619\n",
      "---\n",
      "Post: https://bsky.app/profile/did:plc:26xvddqtbyafothayvgvflzz/post/3jxxtyxhn4g2l\n",
      "Timestamp: 20230612145333\n",
      "---\n",
      "Post: https://bsky.app/profile/did:plc:hwspbpfumiqyqzfeik7vilbu/post/3jxxt7jq7fa2j\n",
      "Timestamp: 20230612145331\n",
      "---\n",
      "\n",
      "Total number of posts user liked: 467\n",
      "\n",
      "Direct Recommendations (using original embeddings):\n",
      "\n",
      "Post: https://bsky.app/profile/did:plc:ilsyluda2ek7zviuxr7k23yd/post/3jwr3ccfj2d2v\n",
      "Cosine Similarity: 0.897, Not liked\n",
      "---\n",
      "\n",
      "Post: https://bsky.app/profile/did:plc:vipregezugaizr3kfcjijzrv/post/3jvntkqedvl26\n",
      "Cosine Similarity: 0.897, Not liked\n",
      "---\n",
      "\n",
      "Post: https://bsky.app/profile/did:plc:oihd7pohncioyoyraqlunaay/post/3jvujsbpwtm2u\n",
      "Cosine Similarity: 0.897, Not liked\n",
      "---\n",
      "\n",
      "Post: https://bsky.app/profile/did:plc:gtbohpin5op22ispn4gdnt7n/post/3juom5ypapc27\n",
      "Cosine Similarity: 0.897, Not liked\n",
      "---\n",
      "\n",
      "Post: https://bsky.app/profile/did:plc:d2lskr7x26clakke7erjgt3k/post/3jxnvrsmfdn2r\n",
      "Cosine Similarity: 0.895, Not liked\n",
      "---\n",
      "\n",
      "Model Recommendations (for comparison):\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 59\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mModel Recommendations (for comparison):\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 59\u001b[0m model_rec_posts, model_scores \u001b[38;5;241m=\u001b[39m get_recommendations(user_id, n_recommendations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m post_id, score \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(model_rec_posts, model_scores):\n\u001b[1;32m     62\u001b[0m     status \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mActually liked\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m post_id \u001b[38;5;129;01min\u001b[39;00m liked_posts \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot liked\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "def get_direct_recommendations(user_id, n_recommendations=5):\n",
    "    \"\"\"Get recommendations using original embeddings directly\"\"\"\n",
    "    user_embedding = final_df[final_df['source_node'] == user_id]['user_embedding'].iloc[0]\n",
    "    all_posts = final_df[['destination_node', 'embeddings']].drop_duplicates('destination_node')\n",
    "    \n",
    "    similarities = [\n",
    "        np.dot(post_emb, user_embedding) / (np.linalg.norm(post_emb) * np.linalg.norm(user_embedding))\n",
    "        for post_emb in all_posts['embeddings']\n",
    "    ]\n",
    "    \n",
    "    top_k_indices = np.argsort(similarities)[-n_recommendations:][::-1]\n",
    "    top_k_scores = [similarities[i] for i in top_k_indices]\n",
    "    recommendations = all_posts.iloc[top_k_indices]\n",
    "    \n",
    "    return recommendations['destination_node'].tolist(), top_k_scores\n",
    "\n",
    "# Test for a few users\n",
    "test_users = final_df['source_node'].unique()[1000:1006]\n",
    "\n",
    "for user_id in test_users:\n",
    "    user_did = reverse_user_mapping.get(user_id)\n",
    "    print(f\"\\nUser: https://bsky.app/profile/{user_did}\")\n",
    "    \n",
    "    # Show user's recent likes\n",
    "    user_likes = final_df[\n",
    "        (final_df['source_node'] == user_id)\n",
    "    ].sort_values('timestamp', ascending=False).head(5)\n",
    "    \n",
    "    print(\"\\nUser's 5 Most Recent Likes:\")\n",
    "    for _, like in user_likes.iterrows():\n",
    "        post_id = like['destination_node']\n",
    "        author_did, post_ref = get_post_info(post_id)\n",
    "        if author_did and post_ref:\n",
    "            print(f\"Post: https://bsky.app/profile/{author_did}/post/{post_ref}\")\n",
    "            print(f\"Timestamp: {like['timestamp']}\")\n",
    "            print(\"---\")\n",
    "    \n",
    "    # Get user's all liked posts\n",
    "    liked_posts = set(final_df[final_df['source_node'] == user_id]['destination_node'])\n",
    "    print(f\"\\nTotal number of posts user liked: {len(liked_posts)}\")\n",
    "    \n",
    "    print(\"\\nDirect Recommendations (using original embeddings):\")\n",
    "    rec_posts, rec_scores = get_direct_recommendations(user_id, n_recommendations=5)\n",
    "    \n",
    "    for post_id, score in zip(rec_posts, rec_scores):\n",
    "        status = \"Actually liked\" if post_id in liked_posts else \"Not liked\"\n",
    "        \n",
    "        # Get post info\n",
    "        author_did, post_ref = get_post_info(post_id)\n",
    "        if author_did and post_ref:\n",
    "            print(f\"\\nPost: https://bsky.app/profile/{author_did}/post/{post_ref}\")\n",
    "        else:\n",
    "            print(f\"\\nPost ID {post_id} not found in mapping\")\n",
    "            \n",
    "        print(f\"Cosine Similarity: {score:.3f}, {status}\")\n",
    "        print(\"---\")\n",
    "\n",
    "    print(\"\\nModel Recommendations (for comparison):\")\n",
    "    model_rec_posts, model_scores = get_recommendations(user_id, n_recommendations=5)\n",
    "    \n",
    "    for post_id, score in zip(model_rec_posts, model_scores):\n",
    "        status = \"Actually liked\" if post_id in liked_posts else \"Not liked\"\n",
    "        \n",
    "        author_did, post_ref = get_post_info(post_id)\n",
    "        if author_did and post_ref:\n",
    "            print(f\"\\nPost: https://bsky.app/profile/{author_did}/post/{post_ref}\")\n",
    "        else:\n",
    "            print(f\"\\nPost ID {post_id} not found in mapping\")\n",
    "            \n",
    "        print(f\"Model Score: {score:.3f}, {status}\")\n",
    "        print(\"---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
